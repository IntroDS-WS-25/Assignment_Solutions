{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='bar_title'></div>\n",
    "\n",
    "*Introduction to Data Science (IDS)*\n",
    "\n",
    "# Assignment 5 - Getting Data in Python Solutions\n",
    "\n",
    "Gunther Gust / Vanessa Haustein <br>\n",
    "Chair for Enterprise AI<br>\n",
    "Data Driven Decisions (D3) Group<br>\n",
    "Center for Artificial Intelligence and Data Science (CAIDAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/d3.png\" style=\"width:20%; float:left;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/CAIDASlogo.png\" style=\"width:20%; float:left;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Random Cat Facts\n",
    "Connect to the [catfact API](https://catfact.ninja/fact) and retrieve one random fact about cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://catfact.ninja/fact'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(url)\n",
    "\n",
    "# print a status update for the requests command\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# store API response to variable\n",
    "response_dict = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fact': 'Cats are subject to gum disease and to dental caries. They should have their teeth cleaned by the vet or the cat dentist once a year.',\n",
       " 'length': 133}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Fetching Random User Data\n",
    "In this exercise, you’ll use the Random User Generator API to retrieve and display information about randomly generated users. This API is free and doesn’t require an API key.\n",
    "\n",
    "Write a Python function to make a GET request to the Random User Generator API and display details for a few random users.\n",
    "\n",
    "Make sure to handle status code errors in you function and display the retrieved data in a readable manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_users(count=1):\n",
    "    url = f\"https://randomuser.me/api/?results={count}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['results']\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1:\n",
      "Name: Marcos Téllez\n",
      "Country: Mexico\n",
      "Email: marcos.tellez@example.com\n",
      "--------------------------------------------------\n",
      "User 2:\n",
      "Name: Gökhan Akman\n",
      "Country: Turkey\n",
      "Email: gokhan.akman@example.com\n",
      "--------------------------------------------------\n",
      "User 3:\n",
      "Name: Martha Gonzalez\n",
      "Country: Switzerland\n",
      "Email: martha.gonzalez@example.com\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_count = 3  # Adjust this to get more or fewer users\n",
    "random_users = get_random_users(user_count)\n",
    "\n",
    "if random_users:\n",
    "    for i, user in enumerate(random_users, start=1):\n",
    "        name = f\"{user['name']['first']} {user['name']['last']}\"\n",
    "        country = user['location']['country']\n",
    "        email = user['email']\n",
    "        print(f\"User {i}:\")\n",
    "        print(f\"Name: {name}\")\n",
    "        print(f\"Country: {country}\")\n",
    "        print(f\"Email: {email}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Scraping Book Information\n",
    "\n",
    "Scrape title and price of all books on http://books.toscrape.com/ and export them to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://books.toscrape.com/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A Light in the Attic - Â£51.77\n",
      "2. Tipping the Velvet - Â£53.74\n",
      "3. Soumission - Â£50.10\n",
      "4. Sharp Objects - Â£47.82\n",
      "5. Sapiens: A Brief History of Humankind - Â£54.23\n",
      "6. The Requiem Red - Â£22.65\n",
      "7. The Dirty Little Secrets of Getting Your Dream Job - Â£33.34\n",
      "8. The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull - Â£17.93\n",
      "9. The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics - Â£22.60\n",
      "10. The Black Maria - Â£52.15\n"
     ]
    }
   ],
   "source": [
    "books = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "book_data = []\n",
    "for book in books:\n",
    "    title = book.h3.a['title']\n",
    "    price = book.find('p', class_='price_color').text\n",
    "\n",
    "    book_data.append({\n",
    "        'Title': title,\n",
    "        'Price': price\n",
    "    })\n",
    "\n",
    "# Display the first few books\n",
    "for idx, book in enumerate(book_data[:10], 1):\n",
    "    print(f\"{idx}. {book['Title']} - {book['Price']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(book_data)\n",
    "df.to_csv('books_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Scraping Peace Nobel Prize Winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to https://en.wikipedia.org/wiki/List_of_Nobel_laureates and check the html code. The task is to extract the name(s) of Peace Nobel Prize Winners of a given year.\n",
    "Write a function `find_peace_winners(target_year)` that returns all names.\n",
    "\n",
    "Hint: Work from top to bottom: first, locate the table that you want to search. Then go through the rows to find the correct year (that will probably be a string...) and then search for the correct column and extract the text of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Nobel_laureates\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"MyScraper/1.0 (contact: vanessa.haustein@uni-wuerzburg.de)\"\n",
    "}\n",
    "\n",
    "# Send a GET request to the page\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "table = soup.find('table', {'class': 'wikitable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peace_winners(target_year):\n",
    "    # Iterate over the table rows, skipping the header row\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        # Extract the year for this row\n",
    "        row_year = row.find('th').get_text(strip=True)\n",
    "        \n",
    "        # If the row's year matches the target year, find the names\n",
    "        if row_year == str(target_year):\n",
    "            # Get the cells in this row\n",
    "            columns = row.find_all('td')\n",
    "            \n",
    "            # Check if the row contains the expected data\n",
    "            if len(columns) > 0:\n",
    "                # Extract the cell containing the winners' names\n",
    "                winner_names_cell = columns[4]\n",
    "                winner_names = winner_names_cell.get_text(strip=True).split(';')\n",
    "                \n",
    "                return winner_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bertha von Suttner']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_peace_winners('1905')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
